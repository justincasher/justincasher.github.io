---
layout: ML_Project
permalink: /catan_rl
feedformat: card
title: Learning Catan through self-play (2024)
---
<br>
**Abstract.** &nbsp; We teach a neural network how to play the game of Catan using reinforcement learning by the means of self-play.


## Table of Contents

1. Introduction
2. Catan implementation
3. Network architecture
4. Training procedure
5. Results


## 1. Introduction

&emsp; The board game of Catan was created in 1995. During the game, players take turns rolling dice, trading resource cards, purchasing development cards, and building roads and settlements, until they reach 10 points. When playing online with friends, I noticed that the bots were atypically poor. Instead of developing strong strategies, they would pursue simple ones, such as drawing lots of development cards. The purpose of this project is to train a competetive Catan playing neural network.

&emsp; Training neural networks to play games via reinforcement learning has been demonstrated to be a strong machine learning method. In 1995, G. Tesauro trained a network less than 5 hidden layers and 100 hidden units to play backgammon at a world class level. It learned by playing itself; in particular, it predicted the win probability for each move each turn, and then chose move with the highest probability. 

&emsp; In the 2010s, taking advantage of greatly increased computing power, researchers at Google used reinforcement learning to attack more complicated games. They trained a single network to play multiple Atari video games. They took advantage of convolutions to play chess. 

&emsp; Our approach...



## 2. Catan implementation



## 3. Network architecture



## 4. Training procedure



## 5. Results 

